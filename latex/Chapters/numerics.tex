% Chapter 3 - Numerical algorithms

\chapter{Numerical algorithms} % Main chapter title

\label{numerics} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

\lhead{Chapter 3. \emph{background on numerical methods}} % Change X to a consecutive number; this is for the header on each page - perhaps a shortened title

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

\colorbox{green}{Ta med konkrete konvergensteoremer! }

\colorbox{green}{Rettskrivning! }

\colorbox{green}{Dropp hattfunksjoner, make ediff pretty! figur som viser energispekteret, ha et konkret eksempel med filtrering }

\section{Galerkin formulation}

\colorbox{green}{obs! sterk formulering, dette må rettes opp i }
Throughout this thesis all numerical methods will be based on the Galerkin formulation. Let us consider a general boundary value problem (BVP)
\begin{align}
	\begin{split}
	\mathcal{L}u =& f \;\; \text{ in } \Omega\\
	\mathcal{B}u =& g \;\; \text{ on } \partial\Omega.
	\end{split}
	\label{eq:BVP}
\end{align}
The domain $\Omega$ is a closed subspace of $\mathbb{R}^d$, $\mathcal{L}: X(\Omega)\rightarrow Y(\Omega)$ and $\mathcal{B}: X(\partial\Omega)\rightarrow B(\partial\Omega)$ are two linear operators,
$f\in Y(\Omega)$ and $g\in B(\partial\Omega)$ are known functions and $u \in X(\Omega)$ is the wanted solution. 
The space $X(\Omega)$ will be denoted as the search space. A weak formulation can now be obtained by multiplying the first equation in \ref{eq:BVP} 
by a test function $v \in X^t(\Omega)$ and integrating over the domain $\Omega$. By choosing $X^t(\Omega) = X(\Omega)$ the Galerkin formulation is obtained.
For more examples and information on this subject the first chapters in \cite{Quarteroni} are recommended. 

By the Lax-Milgram theorem it is known that a BVP is well-posed if the Operator $\mathcal{L}$ is both bounded and coersive.   

Solving the BVP numerically involves choosing discrete subsets of $X,X^t,Y,B$. These will be denoted $X_h,X_h^t,Y_h,B_h$.
The discrete subspaces can be chosen in a number of ways and the defining basis functions vary from one numerical method to another. 
In this thesis the spectral and finite element basis will be shortly stated and the spectral element basis will be viewed in more detail.


\colorbox{green}{vær presis med den svake formuleringen!!}
\section{Finite element method}

Finite element method (FEM) is one of the most widely used numerical methods applied on problems within construction, flow simulation and many 
other areas. It offers a precise mathematical foundation and due to the connectivity properties of the elements 
it guaranties a sparse system. The decomposition of the geometrical domain into a finite amount of elements chosen according to the problem 
wanted to solve, makes it possible to create general algorithms applicable to all kinds of geometries. 
For the full mathematical foundation of FEM it will be referred to \cite{Quarteroni}, but some of the key properties will be stated here
in order to provide a thorough understanding of the spectral element method (SEM). 

FEM provides an algorithm for solving any well-posed BVP \ref{eq:BVP} and the mathematical formulation is obtained by first finding the Galerkin
formulation and choosing a discrete subset $X^p_h(\Omega) \subset X(\Omega)$ spanned by the finite element basis functions ${\phi^p_i}$.
$p$ denotes the polynomial degree of the basis-functions, in 1D and for $p=1$ the basis functions are defined as
\[ \phi_i(x) =
    \begin{cases}
        \frac{x-x_i}{x_i-x_{i-1}}  & \quad \text{if } x_{i-1}\leq x \leq x_i, \\
        \frac{x_{i+1}-x}{x_{i+1}-x_i}  & \quad \text{if } x_{i}\leq x \leq x_{i+1}, \\
        0  & \quad \text{otherwise}. \\
    \end{cases}
\]
Notice that $\text{supp}(\phi_i) = [x_{i-1},x_{i+1}]$ and as a consequence of this $(\phi_i,\phi_j)_{\Omega} = 0 \text{ if } |i-j| > 1 $. 
These qualities is what gives rise to the resulting sparse linear system. 
By increasing the polynomial order the number of grid points used to define the polynomial will need to increase as well.
This implies either reducing the distance between the grid points or increasing the support of each basis function.
Both approaches will reduce the sparsity of the final matrix.
Another key aspect of FEM is the treatment of the domain $\Omega$, 
on which a triangulation $\{\mathcal{T}_h\}$ is defined such that the original domain is divided into elements.
By defining a reference element $[-1,1]^d$ and a general mapping function, all the local contributions can be calculated by a 
generalized quadrature rule before being added to the global system of equations. This is a process tailored for parallelization, and can 
be generalized for a wide range of problems.

FEM is called a projection method since the solution $u_h\in X^h$ is a projection
of the actual solution $u$ of the BVP onto the discrete space $X^h$. Provided that the initial BVP is well-posed there exists to 
constants $M,\alpha>0$ known as the bounded and coercivity constant such that the error of the solution can be reduced to a pure 
interpolation error. The result is known as Cea's lemma,  
\begin{align}
    ||u-u_h||_X \leq \frac{M}{\alpha}||u-I_hu||_X.
    \label{eq:Cea}
\end{align}
Where $I_h$ is the projection operator. 

Before this section ends it is important to understand the two ways to increase accuracy and the effects these two ways have on the algorithm. 
Assume the solution of the BVP to be infinitely smooth and let $h$ denote the general size of the elements
and $p$ the order of the polynomial basis that defines $X^h$. Roughly speaking the error is given as $e = Ch^p$, $C$ being some positive constant.
This is not a formal truth but rather a simple expression to get some intuition on how the error behaves. 
Factors such as geometric complexity, condition-number,non-linear operators and the regularity of the 
solution will all provide slightly more complicated error estimates. 
However for a simpler BVP such as $u,f,g \in C^{\infty}(\Omega), \Omega = [-1,1]^d, \mathcal{L} = -\Delta,\mathcal{B} = 0$ the error estimate is valid.  
performing a $h$-refinement will lead to an algebraic convergence of order $p$, while the sparsity of the system is conserved
and the total algorithm does not change in any other way than increasing the number of elements.
Keeping $h$ constant and increasing $p$ will provide spectral convergence, but the sparsity will be reduced and all integrals solved will require 
quadrature rules of higher order. A formal statement and numerical validation of the error estimate can be found in \cite{Karniadakis} chapter 2.6.  

%-----------------------------------
%	SUBSECTION 1
%-----------------------------------
\section{Spectral methods}
Spectral methods (SM) share a some of the mathematical ideas as FEM, but are not as widely used in real life problems. 
There are many ways to apply SM, 
and in this thesis only the Galerkin version with numerical integration (known as G-NI) will be considered and will be referred to only as SM. 
For a full introduction to SM and its applications to BVP see~\cite{Canuto}.
SM can be reduced to a interpolation problem such as FEM, and are very interesting from a theoretical point of view due to its 
spectral convergence rate which allows you to obtain solutions of extremely high accuracy. 
The most important draw-back of SM are the difficulties with applications to complex geometries. Although the system of equations surging from
a BVP can be constructed in an elegant way it is rarely sparse and often result in expensive calculations. 

Applying SM on a BVP in one dimension requires a set of basis functions $\{\psi_i\}_N$ defined on the whole domain $\Omega$. 
The discrete space $X_h(\Omega)$ spanned by the basis functions involves all polynomials up to degree $N$.
A function $u$ is projected onto $X_h$ by the relation

\begin{align}
    u_h(x) = \sum_{i=0}^N a_i\psi_i(x).
    \label{eq:spectralprojection}
\end{align}
Where the coefficients $a_i$ are called the expansion coefficients. There are many possible choices for the basis and the belonging coefficients, 
in this thesis and the algorithms used the functions $\psi_i$ will be the Lagrange polynomials based on the Gauss-Lobatto-Legendre (GLL) nodes. 
The reason for choosing these nodes is because it enables us to apply the Gauss-Lobatto quadrature 
rule. This is one of several existing Gauss-quadratures, and the only one allowing fixed 
endpoints which is the case for this thesis. For more detailed information on GL-quadrature and 
other quadrature rules it is referred to~\cite{SM}.

The GLL-nodes $\left\{ \xi_i \right\}_{N+1}$ are given as the solutions of the equation 
\begin{align}
    (1-\xi^2)L_N'(\xi) = 0.
    \label{eq:GLL-nodes}
\end{align}
$L_N$ being the Legendre polynomial of degree $N$, defined from the Sturm-Louville problem
\begin{align}
    \frac{d}{dx}\left[  (1-x^2)\frac{d}{dx}L_n(x)\right]+n(n+1)L_n(x) = 0.
    \label{eq:Legendre}
\end{align}
With equations \ref{eq:GLL-nodes} and \ref{eq:Legendre} the local spectral 
basis functions $\psi_j$ can be stated as 
\begin{align}
    \psi_j(x) = \prod_{i\neq j}^{N}\frac{x-x_i}{x_j-x_i}.
    \label{eq:Lagrange}
\end{align}
\colorbox{yellow}{How much details on these polynomials and quadratures should be included? }

$\{x_i\}$ being the solutions to \ref{eq:GLL-nodes}. Note that $\psi_j(x_i) = \delta_{ij}$.
The expansion coefficients in \ref{eq:spectralprojection} are then chosen as $a_i = u_i :=u(x_i)$. 
%to minimize the projection error in $L^2(\Omega)$. 
This definition of the expansion coefficients is very convenient since the actual value of 
the function in any point can just be read directly from the coefficients without having to 
sum all the contributions from the different polynomials.
Creating a basis for 2 and 3 dimensions is done simply by taking the tensor product 
of the basis functions in each direction, for 3 dimensions the basis functions $\Psi$
is given as 
\begin{align}
    \Psi_{l}(\mathbf{x}) = \psi_i(x)\psi_j(y)\psi_k(z).
    \label{eq:3dbasis}
\end{align}
This expansion to multiple dimensions preserves the $\Psi_l(\mathbf{x}_m) = \delta_{lm}$
In order to clarify some of the concepts the SM approach will be applied on the Helmholtz equation
%
\begin{align}
    -\Delta u + \lambda u &= f \quad \text{in } \Omega, \\
    u &= 0 \quad \text{on } \partial \Omega.
    \label{eq:Helmholtz}
\end{align}
%
$\Omega$ will for this example be defined as the unit square $[-1,1]^2$. 
Let us start by defining the space $V =H^1_0(\Omega)$ and assuming $f\in L^2(\Omega)$. The weak formulation after applying the divergence theorem is the given as

Find $u\in V$ st. 
%
\begin{align}
    \int_{\Omega}\nabla u \cdot \nabla v d \Omega + \lambda \int_{\Omega} u vd \Omega 
    &= \int_{\Omega}f vd \Omega \qquad \forall v \in V
    \label{eq:Helmholtzweak}
\end{align}
%
In order to solve this using SM the discrete space $V_h \subset V$ is defined as $\text{span}\{\Psi_l\}$ following the preceding definitions 
the discrete weak formulation is stated as 
Find $u_h\in V_h$ st. 
%
\begin{align}
    \sum_l\left(  u_l\int_{\Omega}\nabla \Psi_l \cdot \nabla \Psi_m d \Omega + u_l\lambda \int_{\Omega} \Psi_l \Psi_md \Omega \right)
    &= \int_{\Omega}f \Psi_md \Omega \qquad \forall \Psi_m \in V_h.
    \label{eq:Helmholtzdiscrete}
\end{align}
%
The following step of this particular SM method is evaluating the integrals by using the GLL-quadrature rule, the resulting system of equations 
is then given as 
%
\begin{align}
    \sum_l\left(  u_l\sum_n \rho_n\nabla \Psi_l(\mathbf{x}_{n}) \cdot \nabla \Psi_m(\mathbf{x}_{n}) + u_l\lambda \sum_n \rho_n \Psi_l(\mathbf{x}_{n}) \Psi_m(\mathbf{x}_{n})\right)\\
     = \sum_n \rho_nf \Psi_m(\mathbf{x}_{n})\qquad \forall \Psi_m(\mathbf{x}_{n}) \in V_h.
    \label{eq:Helmholtzquad}
\end{align}
%
$\rho_n$ is the quadrature weight for the nth node, and $\mathbf{x}_n$ is the vector containing the coordinates to the nth node.
Note that all the indices $l,m,n=1,\cdots,N_xN_y$.
This can be written in a compact matrix form as 
\begin{align}
    (A+\lambda M)u_h = \tilde f.
    \label{eq:Helmholtzmat}
\end{align}
Where the elements in the matrices and vectors are given as 
\begin{align}
    \begin{split}
        A_{lm} &= \sum_n \rho_n\nabla \Psi_l(\mathbf{x}_{n}) \cdot \nabla \Psi_m(\mathbf{x}_{n}),\\
        M_{lm} &= \sum_n \rho_n \Psi_l(\mathbf{x}_{n}) \Psi_m(\mathbf{x}_{n}) = \rho_l\delta_{lm},\\
        (u_h)_l & = u(\mathbf{x}_l), \\
        \tilde f_m &= \sum_n \rho_n f(\mathbf{x}_{n}) \Psi_m(\mathbf{x}_{n}) = \rho_m f(\mathbf{x}_{j}).
    \end{split}
    \label{eq:Helmholtzmatelem}
\end{align}
From these equations it is clear that the mass matrix $M$ is diagonal and the right hand side vector $\tilde f$ is easily calculated, 
while the stiffness matrix $A$ is symmetric but full.

%-----------------------------------
%	SUBSECTION 2
%-----------------------------------

\section{Spectral element method}
In the early 1980's the idea to combine FEM and SM came along in order to obtain the 
robustness and sparse properties of FEM 
combined with the spectral convergence rate provided by SM. 
The result was the Spectral element method. Several formulations was investigated mainly by 
Patera and Maday in the papers \cite{maday1989}, \cite{Patera1984}, \cite{Patera1986} with 
important contributions from Fischer, Rønquist and several more.
It is important to understand that when solving the N-S equations the efficiency of the solution 
method is extremely important. The algorithm has to be parallelizable and the development of the
super computers and computational clusters has played an important role in 
deciding the method applied today. 
The idea is to divide the domain of the BVP into elements as in FEM and then use spectral basis 
functions of higher degree with support only within one single element. 

In the previous subsection the power of spectral methods was illustrated on the unit square in two dimensions.
But the limitations when it comes to more complex geometry rapidly affects the spectral convergence rate. 
Let $\hat{\Omega}$ be the reference element $[-1,1]^d$,
the standard procedure when working on a deformed geometry $\Omega$ with SM is to first create a map 
$\mathcal{F}:\hat{\Omega}\rightarrow\Omega$. An example of this map is the Gordon-Hall procedure 
described in chapter~\ref{GH}.
The Jacobian is then given as the transposed tensor derivative of $\mathcal{F}$
\begin{align}
    \mathbf{J} &= (\nabla \otimes \mathcal{F})^T =
\begin{bmatrix}
    \frac{\partial \mathcal{F}_1}{\partial x} &  \frac{\partial \mathcal{F}_1}{\partial y}  \\ 	
	\frac{\partial \mathcal{F}_2}{\partial x} &  \frac{\partial \mathcal{F}_2}{\partial y} \\ 	
\end{bmatrix},\\
J &= \text{det}(\mathbf{J}).
    \label{eq:jaobian}
\end{align}
This allows us to transform both derivatives and integrals to the reference domain, let $\boldsymbol\xi = [\xi,\eta]^T$ denote the axis in the reference 
domain corresponding to $\mathbf{x} = [x,y]^T$ in the deformed domain. The transformation is performed according to the following identities
\begin{align}
    \begin{split}
        d\mathbf{x} &= \mathbf{J}d\boldsymbol\xi \\
        \int_{\Omega}f(\mathbf{x})d\mathbf{x} &= \int_{\hat\Omega}\hat f J d\boldsymbol\xi \\
        \nabla u &= \mathbf{J}^{-T}\hat\nabla \hat u.
    \end{split}
    \label{eq:transforms}
\end{align}
Here $\hat u,\hat f$ are obtain by simply substituting $\mathbf{x}$ with $\mathcal{F}(\boldsymbol{\xi})$ and $\hat \nabla $ is the partial 
differential operator wrt. $\boldsymbol\xi$. The important thing to notice here is that whenever an integral is solved and a derivative is 
introduced the Jacobian appears in the equation. When applying the GLL-quadrature to solve the integrals equality is guaranteed if and 
only if the function integrated is of polynomial degree $2n-1$ or less, 
and the error gets bigger with increasing polynomial degree.

Although the whole domain $\Omega$ is deformed, the deformation of each
element $\left\{ \Omega_k \right\}$ is normally a lot less crucial.

Let us again consider the Helmholtz problem~\ref{eq:Helmholtz}, but this time 
on a more general domain $\Omega$. The set of elements $\left\{ \Omega_k \right\}$
is defined such that $\Omega_i\bigcap\Omega_j$ is either empty, a vertex or a line and 
$\Omega = \bigcup^K_{k=1}\Omega_k$.
The weak formulation in equation~\ref{eq:Helmholtzweak} can then be written according 
to the SEM formulation

For all elements $\Omega_k$ Find $u_{h,k}\in X^N_k$  such that
%
\begin{align}
    \int_{\Omega_k}\nabla u \cdot \nabla v d \Omega + \lambda \int_{\Omega_k} u vd \Omega 
    &= \int_{\Omega_k}f vd \Omega \qquad \forall v \in X_k^N.
    \label{eq:HelmholtzweakSEM}
\end{align}
%
Where $X^N_k =  H^1(\Omega_k)\bigcap\mathbb{P}^N(\Omega_k)$. The same discretization 
procedure as performed for the pure spectral case is now done for each of the 
sub domains $\Omega_k$,
%
\begin{align}
    \sum_i\left(  u_i\int_{\Omega_k}\nabla \psi_i \cdot \nabla \psi_j d \Omega + 
    u_i\lambda \int_{\Omega_k} \psi_i \psi_jd \Omega \right)
    &= \int_{\Omega_k}f \psi_jd \Omega \qquad \forall \psi_j \in V_h.
    \label{eq:HelmholtzdiscreteSEM}
\end{align}
%
Since the elements can be deformed a Gordon-Hall map is 
constructed to map the coordinates to the reference element $\hat{\Omega}=[-1,1]^d$.
Applying the identities from~\ref{eq:transforms} to~\ref{eq:HelmholtzdiscreteSEM} yields
%
\begin{align}
    \begin{split}
    \sum_i\left(  u_i\int_{\hat{\Omega}_k}(\mathbf{J}^{-T}\hat{\nabla} \hat{\psi}_i)^T
    (\mathbf{J}^{-T}\hat{\nabla} \hat{\psi}_j) J d \hat{\Omega} + 
    u_i\lambda \int_{\hat{\Omega}_k} \hat{\psi}_i \hat{\psi}_j Jd \hat{\Omega} \right)
    &= \int_{\hat{\Omega}_k}\hat{f} \psi_j J d \hat{\Omega} \qquad \forall \psi_j \in V_h.  \\
    \sum_i\left(  u_i\int_{\hat{\Omega}_k}\hat{\nabla}^T \hat{\psi}_i\mathbf{J}^{-1}
    \mathbf{J}^{-T}\hat{\nabla} \hat{\psi}_j J d \hat{\Omega} + 
    u_i\lambda \int_{\hat{\Omega}_k} \hat{\psi}_i \hat{\psi}_j Jd \hat{\Omega} \right)
    &= \int_{\hat{\Omega}_k}\hat{f} \psi_j J d \hat{\Omega} \qquad \forall \psi_j \in V_h.
    \end{split}
    \label{eq:HelmholtzrefSEM}
\end{align}
%
Notice how the integrals depend on the Jacobian $\mathbf{J}$ and its determinant $J$, 


\colorbox{yellow}{Do a more thorough analysis of the meaning of J??}

Hence the local matrices $A_k,M_k$ and the loading vector $f_k$ 
are gathered from each element.
Equivalently as for FEM the global matrices has to be assembled
from all the local matrices corresponding to each sub domain. This procedure is general and can 
be performed on almost any deformed domain as oppose to SM. 

\colorbox{yellow}{Should direct stiffness summation be mentioned ?}

%$\Omega$ is some 2 dimensional strongly connected domain with well-defined corners and each of the edges can be described by some polynomial $\Gamma_i$.

\subsection{Filtering}
Although SEM provides spectral convergence in space and 2nd or 3rd order accuracy in time the stability of a straight forward
implementation is not guaranteed, spurious nodes appear 
as shown in chapter 2.4.1.2 in~\cite{Karniadakis}.
In \cite{FischerMullen} a filter-based stabilization is introduced for SEM applied on 
Navier Stokes equation. The idea is to project a part $ 0 <\alpha < 1$ 
of the highest mode onto a polynomial space of lower order, 
explicitly they define the filter $F_{\alpha}$ as 
%
\begin{align}
    F_{\alpha}= \alpha I_{N-1}  + (1-\alpha) I_d.
    \label{eq:filter}
\end{align}
%
Where $I_{N-1}$ is the projector from $\mathbb{P}_N$ to $\mathbb{P}_{N-1}$ and $ I_d$ is the identity operator.
$\alpha$ is recommended to be somewhere in the interval $(0.05,0.3)$.

The explication of why $F_{\alpha}$ has a filtering effect is best explained by considering the 
more general explication by Pasquetti and Xu in~\cite{Pasquetti}. A quick demonstration of 
how the filter works will however be given here. 

Let $u = \sum_{i=0}^{N} \hat{u}_i L_i$ be the solution to some PDE, where $L_i$ denote the Lagrange
polynomial of order $i$ and $\hat{u}_i$ the corresponding coefficient. The effect of the filter
can be given as 
%
\begin{align}
    F_{\alpha} u = 
    (1-\alpha)\hat{u}_{N}L_{N}
    +\hat{u}_{N-1}L_{N-1} +
    (\hat{u}_{N-2}+\alpha \hat{u}_{N})L_{N-2}
    +\sum_{i=0}^{N-3}\hat{u}_{i}L_{i}.
    \label{eq:filtereffect}
\end{align}
%
From this identity the effect of the filter becomes clear, it is simply removing a part of 
the highest order mode $N$ to the mode $N-2$. The rest of the coefficients remain unchanged.
For a full derivation and discussion on this matter it is referred to chapter 6.5.1 in 
\cite{Karniadakis}.

The filter is proved to be a very effective stabilization method and it preserves the 
spectral convergence rate. Another interesting property is that the filtering procedure 
does not imply dissipation of energy, let the energy norm be defined as $E(u) = ||u||_{L_2}^2$.  
By applying Parseval's identity~\cite{Young} the difference in energy between the original solution
and the filtered solution is given as 
\begin{align}
   \epsilon_{diff}&=E(u) - E(F_{\alpha}u) \\
                &= 2\alpha\hat{u}_N(\hat{u}_N||L_N||^2+\hat{u}_{N-2}||L_{N-2}||^2)
    - \alpha^2\hat{u}^2_N(||L_N||^2+||L_{N-2}||^2)\\
    &\approx \frac{2\alpha}{N}\left[  (1-\frac{\alpha}{2})\hat{u}_N^2 + 
    \hat{u}_N\hat{u}_{N-2}\right].
    \label{eq:filterenergy}
\end{align}
Which can take both positive and negative values depending on the sign and size of
$\hat{u}_N\hat{u}_{N-1}$. By applying the known norm of the Legendre polynomials 
the deduced absolute error $\epsilon_{diff}$ of the filtered energy is of order 
$\epsilon_{diff}\sim \alpha/N$. The approximation $||L_N||^2\approx||L_{N-2}||^2\approx 1/N$
have been used to achieve the result in~\ref{eq:filterenergy}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Aliasing}

%\colorbox{green}{add an illustrative example}
When evaluating the integral surging from the non-linear term in the N-S equation 
the polynomial to be integrated is order $2N+(N-1)$. The quadrature rule applied to solve the 
integrals are only exact up to an order $2N-1$, hence the error surging from this evaluation 
can be of significant size. Applying a non-sufficient quadrature to an integral like this is called a ``variational
crime''. Applying a quadrature rule of a not sufficiently high order results in an 
aliasing effect of the lower modes, attempting to compensate for the higher order modes omitted. 
Since a spectral element method arguably has a good accuracy these variational crimes should 
not be committed and it is therefore common practice to solve this particular integral using a
quadrature of order $3N$. The concept and illustrative examples are given in Chapter 2.4 in 
\cite{Karniadakis}. The effect of aliasing is made clear in chapter~\ref{results}.
This is one of the time vs.\ accuracy questions one have to decide for each problem. 
instead of applying the GLL-quadrature "designed" for the basis-functions the functions
has to be evaluated in a new set of GLL-points with $3/2$ as many nodes. This is a costly 
process and should only be applied when absolutely necessary. 

%----------------------------------------------------------------------------------------
%  SECTION 2
%----------------------------------------------------------------------------------------

\subsection{Gordon-Hall algorithm} \label{GH}
\colorbox{green}{Make figure!!}


In order to work on complex geometries some elements require a certain deformation in order to be able 
to describe the entire domain. It is necessary to evaluate all the integrals surging from the weak formulation over 
a reference domain $\hat{\Omega} = [-1,1]^d$ for sakes of efficiency and implementation purposes. The Gordon-Hall 
algorithm is a general method that creates an isometric map from an arbitrary simply connected domain to $\hat{\Omega}$.
Let $\mathbf{\tilde{x}}$ be the mapping function from the reference domain to the physical domain given on the form 
%
\begin{align}
    \mathbf{\tilde{x}}= \sum_i \sum_j \sum_k \mathbf{x}_{ijk}l_i(r) l_j(s) l_k(t).
    \label{eq:mapping}
\end{align}
%
$l_i$ being the ith Lagrange polynomial.
The full description of the algorithm with helpful figures can be found in \cite{Deville} chapter 4.
Without going to much into the mathematical foundation of this method a more intuitive and implementable
presentation of the method will be provided in this chapter. 
For simplicity a two-dimensional domain will be considered here, and the 3D case will be an easy expansion 
of the algorithm presented here. Consider a deformed domain $\Omega \in \mathbb{R}^2$, with $\Gamma_{i,j}$ representing 
the discrete boundary coordinates. The four vertices can then be expressed as 
$\Gamma_{0,0},\Gamma_{0,N},\Gamma_{N,0}\Gamma_{N,N}$. Let $\phi_0,\phi_N$ be defined as 
%
\begin{align}
    \phi_0(\xi) = \frac{1-\xi}{2}, \qquad
    \phi_N(\xi) = \frac{1+\xi}{2}.
    \label{eq:interpolationoperator}
\end{align}
%
Let $\left\{ \xi_0, \ldots ,\xi_N \right\}_{N+1} = \left\{ -1 ,\ldots ,1 \right\}_{N+1}$
be the GLL-points corresponding to the Lagrange polynomial of order $N$. 
An important property for the functions in~\ref{eq:interpolationoperator} is that
$\phi_0(\xi_0) =\phi_N(\xi_N) = 1$ and $\phi_0(\xi_N) =\phi_N(\xi_0) = 0$.

The algorithm provides a stepwise routine depending on the complexity of the domain. The first step is to create 
a mapping to a polygon spanned from the vertices of $\Omega$.
%
\begin{align}
    \begin{split}
    \mathbf{\tilde{x}}_{i,j} 
             &=\Gamma_{0,0}\phi_0(r_i)\phi_0(s_j)\\
             &+\Gamma_{0,N}\phi_0(r_i)\phi_N(s_j)\\
             &+\Gamma_{N,0}\phi_N(r_i)\phi_0(s_j)\\
             &+\Gamma_{N,N}\phi_N(r_i)\phi_N(s_j)\\
    \end{split}
    \label{eq:gh1}
\end{align}
%
If the edges are straight the algorithm ends here, but for curved edges a second step is performed adding 
the deformation of the edges.
%
\begin{align}
    \begin{split}
        \mathbf{\tilde{x}}_{i,j}  = \mathbf{\tilde{x}}_{i,j} 
             &+(\Gamma_{i,0}-\mathbf{\tilde{x}}_{i,0})\phi_0(s_j)\\
             &+(\Gamma_{i,N}-\mathbf{\tilde{x}}_{i,N})\phi_N(s_j)\\
             &+(\Gamma_{0,j}-\mathbf{\tilde{x}}_{0,j})\phi_0(r_i)\\
             &+(\Gamma_{N,j}-\mathbf{\tilde{x}}_{N,j})\phi_N(r_i)\\
    \end{split}
    \label{eq:gh1}
\end{align}
%
In 3D the additional knowledge of the faces may be applied to create mappings from elements with deformed faces as a 
third step. The only difference when applying this algorithm in three dimensions is that you need to include $\phi$
for a third coordinate $t_k$ and the number of vertices, and edges are 8 and 12 instead of 
4 and 4.



