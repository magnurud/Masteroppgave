% Chapter 3 - Numerical algorithms

\chapter{Numerical algorithms} % Main chapter title

\label{numerics} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

\lhead{Chapter 3. \emph{background on numerical methods}} % Change X to a consecutive number; this is for the header on each page - perhaps a shortened title

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

\colorbox{green}{Ta med konkrete konvergensteoremer! }

\colorbox{green}{Rettskrivning! }

\colorbox{green}{Dropp hattfunksjoner, make ediff pretty! figur som viser energispekteret, ha et konkret eksempel med filtrering }

%\section{Galerkin formulation}

%\colorbox{green}{obs! sterk formulering, dette må rettes opp i }
%Throughout this thesis all numerical methods will be based on the Galerkin formulation. Let us consider a general boundary value problem (BVP)
%\begin{align}
	%\begin{split}
	%\mathcal{L}u =& f \;\; \text{ in } \Omega\\
	%\mathcal{B}u =& g \;\; \text{ on } \partial\Omega.
	%\end{split}
	%\label{eq:BVP}
%\end{align}
%The domain $\Omega$ is a closed subspace of $\mathbb{R}^d$, $\mathcal{L}: X(\Omega)\rightarrow Y(\Omega)$ and $\mathcal{B}: X(\partial\Omega)\rightarrow B(\partial\Omega)$ are two linear operators,
%$f\in Y(\Omega)$ and $g\in B(\partial\Omega)$ are known functions and $u \in X(\Omega)$ is the wanted solution. 
%The space $X(\Omega)$ will be denoted as the search space. A weak formulation can now be obtained by multiplying the first equation in \ref{eq:BVP} 
%by a test function $v \in X^t(\Omega)$ and integrating over the domain $\Omega$. By choosing $X^t(\Omega) = X(\Omega)$ the Galerkin formulation is obtained.
%For more examples and information on this subject the first chapters in \cite{Quarteroni} are recommended. 

%By the Lax-Milgram theorem it is known that a BVP is well-posed if the Operator $\mathcal{L}$ is both bounded and coersive.   

%Solving the BVP numerically involves choosing discrete subsets of $X,X^t,Y,B$. These will be denoted $X_h,X_h^t,Y_h,B_h$.
%The discrete subspaces can be chosen in a number of ways and the defining basis functions vary from one numerical method to another. 
%In this thesis the spectral and finite element basis will be shortly stated and the spectral element basis will be viewed in more detail.


%\colorbox{green}{vær presis med den svake formuleringen!!}
\section{Numerical Concepts on The Stokes problem}
In the previous chapter the N-S equations was presented and reformulated in several ways without any details on how to
actually solve the equations. This chapter aims to give a more detailed description of the solution methods applied.
The choice of algorithms and solution spaces required a more thourough analysis which is normally performed on the 
steady Stokes problem. The steady Stokes problem does not include the convection term but the highest order terms are all present
and is therefore a valid equation to perform this necessary analysis \cite{Karniadakis}. Analysis of the time schemes applied
will be left for a later chapter. The steady Stokes problem with homogenous boundary conditions is given as 
%
\begin{align}
    \begin{split}
        %\frac{\partial \mathbf{u}}{\partial t} 
        - \mu \Delta \mathbf{u} + \nabla p &= \mathbf{f}, \\
        \nabla \cdot \mathbf{u} &= 0, \\
        \mathbf{u} &= 0 \text{  on  } \partial \Omega.
    \end{split}
    \label{eq:stokes}
\end{align}
%
Applying the weak formulation to the Stokes problem implies a minimum requirement on the spaces for $\mathbf{u}$ and $p$,
and their testfunctions. These spaces will be defined as 
%
\begin{align}
    \begin{split}
    H_0^1(\Omega) &= \left\{ v \in H^1(\Omega)\; |\; v = 0 \text{  on  } \partial \Omega \right\},\\
    L_0^2(\Omega) &= \left\{ q \in L^2(\Omega)\; |\; \int_{\Omega} q dx = 0 \right\},
    \end{split}
    \label{eq:spaces}
\end{align}
%
The formulation can easily be extended to include inhomogenous Dirchlet conditions on $\mathbf{u}$ by defining a 
lifting function as described in \cite{Quarteroni}. Note also that the pressure is only present through its gradient 
and is therefore not uniquely defined if the extra constraint on the mean is defined, hence the $0$ in $L_0^2$. 
The weak form can now be stated as

Find $(\mathbf{u}, p) \in H^1_0(\Omega)^3\times L^2_0(\Omega)$ such that 
\begin{align}
    \begin{split}
        %(\frac{\partial \mathbf{u}}{\partial t},\mathbf{v})
        %+ \mathcal{C}(\mathbf{u};\mathbf{u},\mathbf{v})
           \mathcal{B}(\mathbf{v},p) 
         +\nu\mathcal{A}(\mathbf{u},\mathbf{v}) &= (\mathbf{f},\mathbf{v}), \\
        \mathcal{B}(\mathbf{u},q) &= 0.
    \end{split}
	\label{eq:NSweak}
\end{align}
$\forall\; (\mathbf{v}, q) \in H^1(\Omega)^3\times L^2(\Omega)$.
%

The numerical solution of this problem requires a discrete formulation of the weak form, with $(\mathbf{u}_h,p_h)\in V\times Q$
as the discrete solution. The discrete spaces $V,Q$ are subspaces of $H_0^1,L^2_0$ equipped with the discrete $H_1$- and $L^2$-norm
denoted $||\cdot||_V$ and $||\cdot||_Q$.
For the discrete weak form to be well-posed it has to meet the requirements stated by the inf-sup condition, 
%
\begin{align}
    \inf_{q\in Q}\sup_{\mathbf{v}\in V}\frac{\mathcal{B}(v,q)}{||\mathbf{v}||_V||q||_Q} \ge \beta.
    \label{eq:infsup}
\end{align}
%
$\beta$ is some positive constant. This condition often known as the Babuska-Brezzi condition is 
often met by creating a staggered grid, such that the pressure and the velocity are 
evaluated at different points. 

\colorbox{red}{Too early for this part??}
For a Spectral Element formulation of this problem which will be elaborated in chapter~\ref{sem},
a common choice of subspaces $(X,Q)$ is $(P_N\cap H^1_0,P_{N-2} \cap L^{2}_{0})$. This will be referred to as the 
$P_NP_{N-2}$-formulation where $P_N$ denotes the space of polynomials up to degree $N$.
It was however proved by Guermond in~\cite{GuermondPnPn} that the fractional step algorithm requires a 
form of the Stokes problem which automatically fullfills the inf-sup condition and therefore does not require any particular 
discrete subspaces to be chosen. For the sake of convenience the polynomial degree of the pressure and the velocity will be 
the same and the discrete pair of subspaces $(X,Q)$ is chosen to $(P_N\cap H^1_0,P_{N} \cap L^{2}_{0})$, known as the $P_NP_N$-formulation.

Before the analysis of the N-S equations can be taken any further the theory behind the Spectral Element Method will be presented in the following
subsections.


\section{Finite element method}

Finite element method (FEM) is one of the most widely used numerical methods applied on problems within construction, flow simulation and many 
other areas. It offers a precise mathematical foundation and due to the connectivity properties of the elements 
it guaranties a sparse system. The decomposition of the geometrical domain into a finite amount of elements chosen according to the problem 
wanted to solve, makes it possible to create general algorithms applicable to all kinds of geometries. 
For the full mathematical foundation of FEM it will be referred to \cite{Quarteroni}, but some of the key properties will be stated here
in order to provide a thorough understanding of the spectral element method (SEM). 
Throughout this section $p$ denotes the polynomial degree of the basis-functions, $h$ represents the average grid spacing, $E$ is the total
number of elements and $d$ is the number of dimensions. 

FEM provides an algorithm for solving any well-posed boundary value problem (BVP) and the mathematical 
formulation is obtained by first finding the Galerkin
formulation with a corresponding search space $X$ and then choosing a discrete subspace $X^p_h\subset X$ spanned by the finite element basis functions $\{\phi^p_i\}_{i\in (1,E)}$.
The key property of the basis functions is that they only have local support in a very small part of the domain. 
This is what gives rise to the resulting sparse linear system. 
By increasing the polynomial order the number of grid points used to define the polynomial will need to increase as well.
This implies either reducing the distance between the grid points or increasing the support of each basis function.
Both approaches will reduce the sparsity of the final matrix.
Another important aspect of FEM is the treatment of the domain $\Omega$, 
on which a triangulation $\{\mathcal{T}_h\}$ is defined such that the original domain is divided into elements.
By defining a reference element and a general mapping function, all the local contributions can be calculated by a 
generalized quadrature rule before being added to the global system of equations. This is a process tailored for parallelization, and can 
be generalized for a wide range of problems.

FEM is called a projection method since the solution $u_h\in X_h^p$ is a projection
of the actual solution $u$ of the BVP onto the discrete space $X_h^p$. Provided that the initial BVP is well-posed there exists to 
constants $M,\alpha>0$ known as the bounded and coercivity constant such that the error of the solution can be reduced to a pure 
interpolation error. The result is known as Cea's lemma,  
\begin{align}
    ||u-u_h||_X \leq \frac{M}{\alpha}||u-I_hu||_X.
    \label{eq:Cea}
\end{align}
Where $I_h$ is the interpolation operator. 

\colorbox{red}{does this interpolation operator need to be defined or explained in any way ?}

Before this section ends it is important to understand the two ways to increase accuracy and the effects these two ways have on the algorithm. 
Assume the solution of the BVP to be infinitely smooth and the domain be sufficiently regular. 
This yields an error $e = Ch^p$, $C$ being some positive constant.
Factors such as geometric complexity, condition-number,non-linear operators and the continuity of the 
solution will all provide slightly more complicated error estimates. 
However for a simpler BVP such as the Poisson problem on the unit square, the error estimate is valid.  
performing a $h$-refinement will lead to an algebraic convergence of order $p$, while the sparsity of the system is conserved
and the total algorithm does not change in any other way than increasing the number of elements.
Keeping $h$ constant and increasing $p$ will provide spectral convergence, but the sparsity will be reduced and all integrals solved will require 
quadrature rules of higher order. A formal statement and numerical validation of the error estimate can be found in \cite{Karniadakis} chapter 2.6.  

%-----------------------------------
%	SUBSECTION 1
%-----------------------------------

\section{Spectral methods}
Spectral methods (SM) share a some of the mathematical ideas as FEM, but are not as widely used in real life problems. 
There are many ways to apply SM, 
and in this thesis only the Galerkin version with numerical integration (known as G-NI) will be considered and will be referred to only as SM. 
For a full introduction to SM and its applications to BVP see~\cite{Canuto}.
SM can be reduced to a interpolation problem such as FEM, and are very interesting from a theoretical point of view due to its 
spectral convergence rate which allows you to obtain solutions of extremely high accuracy. 
The most important draw-back of SM are the difficulties with applications to complex geometries. Although the system of equations surging from
a BVP can be constructed in an elegant way it is rarely sparse and often result in expensive calculations. 

Applying SM on a BVP in one dimension requires a set of basis functions $\{\psi_i\}_N$ defined on the whole domain $\Omega$. 
The discrete space $X_h(\Omega)$ spanned by the basis functions involves all polynomials up to degree $N$.
A function $u$ is projected onto $X_h$ by the relation

\begin{align}
    u_h(x) = \sum_{i=0}^N a_i\psi_i(x).
    \label{eq:spectralprojection}
\end{align}
Where the coefficients $a_i$ are called the expansion coefficients. There are many possible choices for the basis and the belonging coefficients, 
in this thesis and the algorithms used the functions $\psi_i$ will be the Lagrange polynomials based on the Gauss-Lobatto-Legendre (GLL) nodes. 
The reason for choosing these nodes is because it enables us to apply the Gauss-Lobatto quadrature 
rule. This is one of several existing Gauss-quadratures, and the only one allowing fixed 
endpoints which is the case for this thesis. For more detailed information on GL-quadrature and 
other quadrature rules it is referred to~\cite{SM}.

The GLL-nodes $\left\{ \xi_i \right\}_{N+1}$ are given as the solutions of the equation 
\begin{align}
    (1-\xi^2)L_N'(\xi) = 0.
    \label{eq:GLL-nodes}
\end{align}
$L_N$ being the Legendre polynomial of degree $N$, defined from the Sturm-Louville problem
\begin{align}
    \frac{d}{dx}\left[  (1-x^2)\frac{d}{dx}L_n(x)\right]+n(n+1)L_n(x) = 0.
    \label{eq:Legendre}
\end{align}
With equations \ref{eq:GLL-nodes} and \ref{eq:Legendre} the local spectral 
basis functions $\psi_j$ can be stated as 
\begin{align}
    \psi_j(x) = \prod_{i\neq j}^{N}\frac{x-x_i}{x_j-x_i}.
    \label{eq:Lagrange}
\end{align}

$\{x_i\}$ being the solutions to \ref{eq:GLL-nodes}. Note that $\psi_j(x_i) = \delta_{ij}$.
The expansion coefficients in \ref{eq:spectralprojection} are then chosen as $a_i = u_i :=u(x_i)$. 

This definition of the expansion coefficients is very convenient since the actual value of 
the function in any point can just be read directly from the coefficients without having to 
sum all the contributions from the different polynomials.
Creating a basis for 2 and 3 dimensions is done simply by taking the tensor product 
of the basis functions in each direction. let $i,j,k$ denote the one dimesional indexes in each direction running from 
$1$ to $N$ while $m,l,n$ denote three dimensional indexes running from $1$ to $N^d$. 
for 3 dimensions the basis functions $\Psi$ is given as 
\begin{align}
    \Psi_{l}(\mathbf{x}) = \psi_i(x)\psi_j(y)\psi_k(z).
    \label{eq:3dbasis}
\end{align}
This expansion to multiple dimensions preserves the $\Psi_l(\mathbf{x}_m) = \delta_{lm}$.
In order to clarify some of the concepts the SM approach will be applied on the Helmholtz equation
%
\begin{align}
    -\Delta u + \lambda u &= f \quad \text{in } \Omega, \\
    u &= 0 \quad \text{on } \partial \Omega.
    \label{eq:Helmholtz}
\end{align}
%
$\Omega$ will for this example be defined as the unit square $[-1,1]^2$. 
Let us start by defining the space $V =H^1_0(\Omega)$ and assuming $f\in L^2(\Omega)$. The weak formulation after applying the divergence theorem is the given as

Find $u\in V$ st. 
%
\begin{align}
    \int_{\Omega}\nabla u \cdot \nabla v d \Omega + \lambda \int_{\Omega} u vd \Omega 
    &= \int_{\Omega}f vd \Omega \qquad \forall v \in V
    \label{eq:Helmholtzweak}
\end{align}
%
In order to solve this using SM the discrete space $V_h \subset V$ is defined as $\text{span}\{\Psi_l\}$ following the preceding definitions 
the discrete weak formulation is stated as 
Find $u_h\in V_h$ st. 
%
\begin{align}
    \sum_l\left(  u_l\int_{\Omega}\nabla \Psi_l \cdot \nabla \Psi_m d \Omega + u_l\lambda \int_{\Omega} \Psi_l \Psi_md \Omega \right)
    &= \int_{\Omega}f \Psi_md \Omega \qquad \forall \Psi_m \in V_h.
    \label{eq:Helmholtzdiscrete}
\end{align}
%
The following step of this particular SM method is evaluating the integrals by using the GLL-quadrature rule, the resulting system of equations 
is then given as 
%
\begin{align}
    \sum_l\left(  u_l\sum_n \rho_n\nabla \Psi_l(\mathbf{x}_{n}) \cdot \nabla \Psi_m(\mathbf{x}_{n}) + u_l\lambda \sum_n \rho_n \Psi_l(\mathbf{x}_{n}) \Psi_m(\mathbf{x}_{n})\right)\\
     = \sum_n \rho_nf \Psi_m(\mathbf{x}_{n})\qquad \forall \Psi_m(\mathbf{x}_{n}) \in V_h.
    \label{eq:Helmholtzquad}
\end{align}
%
$\rho_n$ is the quadrature weight for the nth node, and $\mathbf{x}_n$ is the vector containing the coordinates to the nth node.
Note that all the indices $l,m,n=1,\cdots,N_xN_y$.
This can be written in a compact matrix form as 
\begin{align}
    (A+\lambda M)u_h = \tilde f.
    \label{eq:Helmholtzmat}
\end{align}
Where the elements in the matrices and vectors are given as 
\begin{align}
    \begin{split}
        A_{lm} &= \sum_n \rho_n\nabla \Psi_l(\mathbf{x}_{n}) \cdot \nabla \Psi_m(\mathbf{x}_{n}),\\
        M_{lm} &= \sum_n \rho_n \Psi_l(\mathbf{x}_{n}) \Psi_m(\mathbf{x}_{n}) = \rho_l\delta_{lm},\\
        (u_h)_l & = u(\mathbf{x}_l), \\
        \tilde f_m &= \sum_n \rho_n f(\mathbf{x}_{n}) \Psi_m(\mathbf{x}_{n}) = \rho_m f(\mathbf{x}_{j}).
    \end{split}
    \label{eq:Helmholtzmatelem}
\end{align}
From these equations it is clear that the mass matrix $M$ is diagonal and the right hand side vector $\tilde f$ is easily calculated, 
while the stiffness matrix $A$ is symmetric but full.

\colorbox{red}{error/ convergence theorem}

%-----------------------------------
%	SUBSECTION 2
%-----------------------------------

\section{Spectral element method} \label{sem}
In the early 1980's the idea to combine FEM and SM came along in order to obtain the 
robustness and sparse properties of FEM 
combined with the spectral convergence rate provided by SM. 
The result was the Spectral element method. Several formulations was investigated mainly by 
Patera and Maday in the papers \cite{maday1989}, \cite{Patera1984}, \cite{Patera1986} with 
important contributions from Fischer, Rønquist and several more.
It is important to understand that when solving the N-S equations the efficiency of the solution 
method is extremely important. The algorithm has to be parallelizable and the development of the
super computers and computational clusters has played an important role in 
deciding the method applied today. 
The idea is to divide the domain of the BVP into elements as in FEM and then use spectral basis 
functions of higher degree with support only within one single element. 

In the previous subsection the power of spectral methods was illustrated on the unit square in two dimensions.
But the limitations when it comes to more complex geometry rapidly affects the spectral convergence rate. 
Let $\hat{\Omega}$ be the reference element $[-1,1]^d$,
the standard procedure when working on a deformed geometry $\Omega$ with SM is to first create a map 
$\mathcal{F}:\hat{\Omega}\rightarrow\Omega$. An example of this map is the Gordon-Hall procedure 
described in chapter~\ref{GH}.
The Jacobian is then given as the transposed tensor derivative of $\mathcal{F}$, which in two dimension is 
written as 
\begin{align}
    \mathbf{J} &= (\nabla \otimes \mathcal{F})^T =
\begin{bmatrix}
    \frac{\partial \mathcal{F}_1}{\partial x} &  \frac{\partial \mathcal{F}_1}{\partial y}  \\ 	
	\frac{\partial \mathcal{F}_2}{\partial x} &  \frac{\partial \mathcal{F}_2}{\partial y} \\ 	
\end{bmatrix},\\
J &= \text{det}(\mathbf{J}).
    \label{eq:jaobian}
\end{align}
This allows us to transform both derivatives and integrals to the reference domain, let $\boldsymbol\xi = [\xi,\eta]^T$ denote the axis in the reference 
domain corresponding to $\mathbf{x} = [x,y]^T$ in the deformed domain. The transformation is performed according to the following identities
\begin{align}
    \begin{split}
        d\mathbf{x} &= \mathbf{J}d\boldsymbol\xi \\
        \int_{\Omega}f(\mathbf{x})d\mathbf{x} &= \int_{\hat\Omega}\hat f J d\boldsymbol\xi \\
        \nabla u &= \mathbf{J}^{-T}\hat\nabla \hat u.
    \end{split}
    \label{eq:transforms}
\end{align}
Here $\hat u,\hat f$ are obtain by simply substituting $\mathbf{x}$ with $\mathcal{F}(\boldsymbol{\xi})$ and $\hat \nabla $ is the partial 
differential operator wrt. $\boldsymbol\xi$. The important thing to notice here is that whenever an integral is solved and a derivative is 
introduced the Jacobian appears in the equation. When applying the GLL-quadrature to solve the integrals equality is guaranteed if and 
only if the function integrated is of polynomial degree $2n-1$ or less, 
and the error gets bigger with increasing polynomial degree. A higher order jacobian could imply a large error in the quadrature.

Although the whole domain $\Omega$ is deformed, the deformation of each
element $\left\{ \Omega_k \right\}$ is normally a lot less crucial. This gives SEM a huge advantage and allows it to 
obtain accurate results even in complicated domains.

Let us again consider the Helmholtz problem~\ref{eq:Helmholtz}, but this time 
on a more general domain $\Omega$. The set of elements $\left\{ \Omega_k \right\}$
is defined such that $\Omega_i\bigcap\Omega_j$ is either empty, a vertex or a line and 
$\Omega = \bigcup^K_{k=1}\Omega_k$.
The weak formulation in equation~\ref{eq:Helmholtzweak} can then be written according 
to the SEM formulation

For all elements $\Omega_k$ Find $u_{h,k}\in X^N_k$  such that
%
\begin{align}
    \int_{\Omega_k}\nabla u \cdot \nabla v d \Omega + \lambda \int_{\Omega_k} u vd \Omega 
    &= \int_{\Omega_k}f vd \Omega \qquad \forall v \in X_k^N.
    \label{eq:HelmholtzweakSEM}
\end{align}
%
Where $X^N_k =  H_0^1(\Omega_k)\bigcap\mathbb{P}^N(\Omega_k)$. The same discretization 
procedure as performed for the pure spectral case is now done for each of the 
sub domains $\Omega_k$,
%
\begin{align}
    \sum_i\left(  u_i\int_{\Omega_k}\nabla \psi_i \cdot \nabla \psi_j d \Omega + 
    u_i\lambda \int_{\Omega_k} \psi_i \psi_jd \Omega \right)
    &= \int_{\Omega_k}f \psi_jd \Omega \qquad \forall \psi_j \in V_h.
    \label{eq:HelmholtzdiscreteSEM}
\end{align}
%
Since the elements can be deformed a Gordon-Hall map is 
constructed to map the coordinates to the reference element $\hat{\Omega}=[-1,1]^d$.
Applying the identities from~\ref{eq:transforms} to~\ref{eq:HelmholtzdiscreteSEM} yields
%
\begin{align}
    \begin{split}
    \sum_i\left(  u_i\int_{\hat{\Omega}_k}(\mathbf{J}^{-T}\hat{\nabla} \hat{\psi}_i)^T
    (\mathbf{J}^{-T}\hat{\nabla} \hat{\psi}_j) J d \hat{\Omega} + 
    u_i\lambda \int_{\hat{\Omega}_k} \hat{\psi}_i \hat{\psi}_j Jd \hat{\Omega} \right)
    &= \int_{\hat{\Omega}_k}\hat{f} \psi_j J d \hat{\Omega} \qquad \forall \psi_j \in V_h.  \\
    \sum_i\left(  u_i\int_{\hat{\Omega}_k}\hat{\nabla}^T \hat{\psi}_i\mathbf{J}^{-1}
    \mathbf{J}^{-T}\hat{\nabla} \hat{\psi}_j J d \hat{\Omega} + 
    u_i\lambda \int_{\hat{\Omega}_k} \hat{\psi}_i \hat{\psi}_j Jd \hat{\Omega} \right)
    &= \int_{\hat{\Omega}_k}\hat{f} \psi_j J d \hat{\Omega} \qquad \forall \psi_j \in V_h.
    \end{split}
    \label{eq:HelmholtzrefSEM}
\end{align}
%
\colorbox{red}{add a short argument for the danger of higher order jacobian}
|||Notice how the integrals depend on the Jacobian $\mathbf{J}$ and its determinant $J$.|||
the integral corresponding to the diffusion operator contains 
The local matrices $A_k,M_k$ and the loading vector $f_k$ are gathered from each element.
Equivalently as for FEM the global matrices has to be assembled
from all the local matrices corresponding to each subdomain. This procedure is general and can 
be performed on almost any deformed domain as oppose to SM. 


\colorbox{red}{Convergence estimate!! }
%$\Omega$ is some 2 dimensional strongly connected domain with well-defined corners and each of the edges can be described by some polynomial $\Gamma_i$.

\subsection{Filtering}
Although SEM provides spectral convergence in space and 2nd or 3rd order accuracy in time the stability of a straight forward
implementation is not guaranteed, spurious nodes appear 
as shown in chapter 2.4.1.2 in~\cite{Karniadakis}.
In \cite{FischerMullen} a filter-based stabilization is introduced for SEM applied on 
Navier Stokes equation. The idea is to project a part $ 0 <\alpha < 1$ 
of the highest mode onto a polynomial space of lower order, 
explicitly they define the filter $F_{\alpha}$ as 
%
\begin{align}
    F_{\alpha}= \alpha I_{N-1}  + (1-\alpha) I_d.
    \label{eq:filter}
\end{align}
%
Where $I_{N-1}$ is the projector from $\mathbb{P}_N$ to $\mathbb{P}_{N-1}$ and $ I_d$ is the identity operator.
$\alpha$ is recommended to be somewhere in the interval $(0.05,0.3)$.

The explication of why $F_{\alpha}$ has a filtering effect is best explained by considering the 
more general explication by Pasquetti and Xu in~\cite{Pasquetti}. A quick demonstration of 
how the filter works will however be given here. 

Let $u = \sum_{i=0}^{N} \hat{u}_i L_i$ be the solution to some PDE, where $L_i$ denote the Lagrange
polynomial of order $i$ and $\hat{u}_i$ the corresponding coefficient. The effect of the filter
can be given as 
%
\begin{align}
    F_{\alpha} u = 
    (1-\alpha)\hat{u}_{N}L_{N}
    +\hat{u}_{N-1}L_{N-1} +
    (\hat{u}_{N-2}+\alpha \hat{u}_{N})L_{N-2}
    +\sum_{i=0}^{N-3}\hat{u}_{i}L_{i}.
    \label{eq:filtereffect}
\end{align}
%
From this identity the effect of the filter becomes clear, it is simply removing a part of 
the highest order mode $N$ to the mode $N-2$. The rest of the coefficients remain unchanged.
For a full derivation and discussion on this matter it is referred to chapter 6.5.1 in 
\cite{Karniadakis}.

The filter is proved to be a very effective stabilization method and it preserves the 
spectral convergence rate. Another interesting property is that the filtering procedure 
does not imply dissipation of energy, let the energy norm be defined as $E(u) = ||u||_{L_2}^2$.  
By applying Parseval's identity~\cite{Young} the difference in energy between the original solution
and the filtered solution is given as 
\begin{align}
   \epsilon_{diff}&=E(u) - E(F_{\alpha}u) \\
                &= 2\alpha\hat{u}_N(\hat{u}_N||L_N||^2+\hat{u}_{N-2}||L_{N-2}||^2)
    - \alpha^2\hat{u}^2_N(||L_N||^2+||L_{N-2}||^2)\\
    &\approx \frac{2\alpha}{N}\left[  (1-\frac{\alpha}{2})\hat{u}_N^2 + 
    \hat{u}_N\hat{u}_{N-2}\right].
    \label{eq:filterenergy}
\end{align}
Which can take both positive and negative values depending on the sign and size of
$\hat{u}_N\hat{u}_{N-1}$. By applying the known norm of the Legendre polynomials 
the deduced absolute error $\epsilon_{diff}$ of the filtered energy is of order 
$\epsilon_{diff}\sim \alpha/N$. The approximation $||L_N||^2\approx||L_{N-2}||^2\approx 1/N$
have been used to achieve the result in~\ref{eq:filterenergy}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Aliasing}

%\colorbox{green}{add an illustrative example}
When evaluating the integral surging from the non-linear term in the N-S equations 
the polynomial to be integrated is order $2N+(N-1)$. The quadrature rule applied to solve the 
integrals are only exact up to an order $2N-1$, hence the error surging from this evaluation 
can be of significant size. Applying a non-sufficient quadrature to an integral like this is called a ``variational
crime''. Applying a quadrature rule of a not sufficiently high order results in an 
aliasing effect of the lower modes, attempting to compensate for the higher order modes omitted. 
Since a spectral element method arguably has a good accuracy these variational crimes should 
not be committed and it is therefore common practice to solve this particular integral using a
quadrature of order $3N$. The concept and illustrative examples are given in Chapter 2.4 in 
\cite{Karniadakis}. The effect of aliasing is made clear in chapter~\ref{results}.
This is one of the time vs.\ accuracy questions one have to decide for each problem. 
instead of applying the GLL-quadrature "designed" for the basis-functions the functions
has to be evaluated in a new set of GLL-points with $3/2$ as many nodes. This is a costly 
process and should only be applied when absolutely necessary. 

%----------------------------------------------------------------------------------------
%  SECTION 2
%----------------------------------------------------------------------------------------

\subsection{Gordon-Hall algorithm} \label{GH}

%
\begin{figure}[h]
	\centering
	\includegraphics[width=1.0\textwidth]{Figures/GordonHall5.png}
	\caption{An illustration of how the Gordon-Hall algorithm creates a map from the 
    deformed element to the reference element. The GLL-points are drawn along the edge
    $\Gamma_{k,0}$ on the deformed element which corresponds to $s=-1$ on the reference
    element.}
	\label{fig:cHfilter}
\end{figure}
%

In order to work on complex geometries some elements require a certain deformation in order to be able 
to describe the entire domain. It is necessary to evaluate all the integrals surging from the weak formulation over 
a reference domain $\hat{\Omega} = [-1,1]^d$ for sakes of efficiency and implementation purposes. The Gordon-Hall 
algorithm is a general method that creates an isometric map from an arbitrary simply connected domain to $\hat{\Omega}$.
Let $\mathbf{\tilde{x}}$ be the mapping function from the reference domain to the physical domain given on the form 
%
\begin{align}
    \mathbf{\tilde{x}}= \sum_i \sum_j \sum_k \mathbf{x}_{ijk}l_i(r) l_j(s) l_k(t).
    \label{eq:mapping}
\end{align}
%
$l_i$ being the ith Lagrange polynomial.
The full description of the algorithm with helpful figures can be found in \cite{Deville} chapter 4.
Without going to much into the mathematical foundation of this method a more intuitive and implementable
presentation of the method will be provided in this chapter. 
For simplicity a two-dimensional domain will be considered here, and the 3D case will be an easy expansion 
of the algorithm presented here. Consider a deformed domain $\Omega \in \mathbb{R}^2$, with $\Gamma_{i,j}$ representing 
the discrete boundary coordinates. The four vertices can then be expressed as 
$\Gamma_{0,0},\Gamma_{0,N},\Gamma_{N,0}\Gamma_{N,N}$. Let $\phi_0,\phi_N$ be defined as 
%
\begin{align}
    \phi_0(\xi) = \frac{1-\xi}{2}, \qquad
    \phi_N(\xi) = \frac{1+\xi}{2}.
    \label{eq:interpolationoperator}
\end{align}
%
Let $\left\{ \xi_0, \ldots ,\xi_N \right\}_{N+1} = \left\{ -1 ,\ldots ,1 \right\}_{N+1}$
be the GLL-points corresponding to the Lagrange polynomial of order $N$. 
An important property for the functions in~\ref{eq:interpolationoperator} is that
$\phi_0(\xi_0) =\phi_N(\xi_N) = 1$ and $\phi_0(\xi_N) =\phi_N(\xi_0) = 0$.

The algorithm provides a stepwise routine depending on the complexity of the domain. The first step is to create 
a mapping to a polygon spanned from the vertices of $\Omega$.
%
\begin{align}
    \begin{split}
    \mathbf{\tilde{x}}_{i,j} 
             &=\Gamma_{0,0}\phi_0(r_i)\phi_0(s_j)\\
             &+\Gamma_{0,N}\phi_0(r_i)\phi_N(s_j)\\
             &+\Gamma_{N,0}\phi_N(r_i)\phi_0(s_j)\\
             &+\Gamma_{N,N}\phi_N(r_i)\phi_N(s_j)\\
    \end{split}
    \label{eq:gh1}
\end{align}
%
If the edges are straight the algorithm ends here, but for curved edges a second step is performed adding 
the deformation of the edges.
%
\begin{align}
    \begin{split}
        \mathbf{\tilde{x}}_{i,j}  = \mathbf{\tilde{x}}_{i,j} 
             &+(\Gamma_{i,0}-\mathbf{\tilde{x}}_{i,0})\phi_0(s_j)\\
             &+(\Gamma_{i,N}-\mathbf{\tilde{x}}_{i,N})\phi_N(s_j)\\
             &+(\Gamma_{0,j}-\mathbf{\tilde{x}}_{0,j})\phi_0(r_i)\\
             &+(\Gamma_{N,j}-\mathbf{\tilde{x}}_{N,j})\phi_N(r_i)\\
    \end{split}
    \label{eq:gh1}
\end{align}
%
In 3D the additional knowledge of the faces may be applied to create mappings from elements with deformed faces as a 
third step. The only difference when applying this algorithm in three dimensions is that you need to include $\phi$
for a third coordinate $t_k$ and the number of vertices, and edges are 8 and 12 instead of 
4 and 4.



\section{Time integration for incompressible N-S} \label{timeNS}
\colorbox{green}{Rewrite this introduction}

A non-linear set of equations requires a non-trivial solution method, and when the domain of the problem can be anything from a simple channel 
to a moving turbine there are many considerations that needs to be made. Although the equations have been known for over 200 years no one 
has been able to prove or disprove the well-posedness of the problem. Some of the most common algorithms 
will be discussed in the following subsections

\subsection{Operator-splitting techniques }
In this chapter $a_j,b_j$ will denote the coefficients for some explicit and implicit scheme.
Let us consider a simplified transient problem 
\begin{align}
    \frac{du}{dt} = f(u,t)u + g(t)u.
    \label{eq:testproblem}
\end{align}
$f$ is here a function of $u$ and $t$, while $g$ is only dependent of the time $t$. Let superscript denote the timestep, 
such that $g^{n}=g(n\Delta t)$ for some fixed timestep $\Delta t$. One step applying a kth order
Backward Difference scheme (BDFk) yields
%
\begin{align}
    \sum_{j = 0}^{k} \frac{b_j}{\Delta t} u^{n+1-j} =f^{n+1}u^{n+1}+g^{n+1}u^{n+1}.
    \label{eq:imp}
\end{align}
%
Now notice that $f^{n+1}=f(u^{n+1},t^{n+1})$ requires that $u$ is known at time $t^{n+1}$ which is not achievable at the current 
step. This term is therefore approximated by a kth order explicit scheme leading to 
%
\begin{align}
    \sum_{j = 0}^{k} \frac{b_j}{\Delta t} u^{n+1-j} =\sum_{j = 0}^{k} a_j f^{n-j}u^{n-j}+g^{n+1}u^{n+1}.
    \label{eq:imp-exp}
\end{align}
%
Now the terms can be ordered such that only the implicit terms are present on the left hand side, 
%
\begin{align}
    (\frac{b_0}{\Delta t} +g^{n+1})u^{n+1} =-\sum_{j = 1}^{k} \frac{b_j}{\Delta t} u^{n+1-j}+\sum_{j = 0}^{k} a_j f^{n-j}u^{n-j}.
    \label{eq:imp-exp-ord}
\end{align}
%
This way of solving~\ref{eq:testproblem} allows easy invertible terms to be solved implicitly while non-linear terms can be extrapolated.
In the Navier-Stokes equation this strategy will be applied to split the non-linear term from the rest.
In this thesis the schemes BDFk and EXTk for $k=2,3$ are applied, the coefficients can be found in~\cite{Nek}. 

%of $u$ and therefore of $t$ as well. Let g be easily invertible By integrating on both sides one obtains
%\begin{align}
    %u(s) - u(0) = \int_0^s f dt + \int_0^s g dt.
    %\label{eq:testproblemintegrated}
%\end{align}
%The idea is then to evaluate one of the integrals by an explicit scheme and the other one with an implicit scheme.
%A general formulation of this for a time step would be on the form 
%\begin{align}
    %u^{n+1}-u^{n} = \sum_{k = 0}^{N} a_k f^{n-k}+\sum_{k = 0}^{N} b_k g^{n-k+1}.
    %\label{eq:exp-imp}
%\end{align}
%In~\ref{eq:exp-imp} the first integral in~\ref{eq:testproblemintegrated} is evaluated by 
%an explicit scheme and the second one by an implicit scheme. The coefficients $a_k,b_k$ corresponds to 
%the elected scheme. When operator splitting is applied in this thesis an kth order Backward difference scheme (BDFk) is 
%chosen for the implicitly evaluated integral while an extrapolation scheme of similar order (EXTk) is applied for the explicit scheme.


%Operator splitting is a very convenient strategy for the N-S equations which consists of the easily invertible Laplacian
%and the demanding convection operator. 


\subsection{Operator integrating factor schemes (OIFS)}
The operator-splitting method described in the previous chapter may lead to an unstable scheme,
OIFS is a similar method but it offers a more stable scheme. The presentation of the method 
is presented here in a computational fashion, for a full description and derivation of the method 
it is referred to Maday et al~\cite{raey}.

By considering the NS-equation in a general operational form 
%
\begin{align}
    M\frac{d \mathbf{v}}{dt} + C\mathbf{v} = -A\mathbf{v} +D p +Mf.
    \label{eq:NSoperator}
\end{align}
%
Now let $Q(t)$ be an operator such that $Q(t^{n+1}) = I$ and 
%
\begin{align}
    \frac{dQ(t)M\mathbf{v}}{dt} &=  Q(t)M\frac{d\mathbf{v}}{dt} + \frac{d}{dt}(Q(t)M)\mathbf{v},\\
    &= Q(t)M\frac{d\mathbf{v}}{dt} + Q(t)C\mathbf{v}. 
    \label{eq:integrationalfactor}
\end{align}
%
This way~\ref{eq:NSoperator} can be written as 
\begin{align}
    \frac{d Q(t)M\mathbf{v}}{dt} =Q(t)( -A\mathbf{v} +D p +M\mathbf{f}).
    \label{eq:NSoperatorOIFS}
\end{align}
Evaluating this equation with a BDFk-scheme results in a system 
\begin{align}
    \sum_{j=0}^{k}\beta_jQ(t^{n+1-j})M\mathbf{v}^{n+1-j} =\Delta t \: Q(t^{n+1})( -A\mathbf{v}^{n+1} +D p^{n+1} +M\mathbf{f}^{n+1}).
    \label{eq:NSOIFS1}
\end{align}
Applying the fact that $Q(t^{n+1}) = I$ enables~\ref{eq:NSOIFS1} to be written as 
\begin{align}
    \beta_0M\mathbf{v}^{n+1} + \sum_{j=1}^{k}\beta_jQ(t^{n+1-j})M\mathbf{v}^{n+1-j} 
    =\Delta t ( -A\mathbf{v}^{n+1} +D p^{n+1} +M\mathbf{f}^{n+1}).
    \label{eq:NSOIFS1}
\end{align}
Notice how all the easily invertible operators are evaluated implicitly, while the convective non-linear term is hidden in the BDFk scheme. 
OIFS allows the terms in the sum to be calculated in a rather elegant fashion.
First of all the auxiliary variable $\tilde{\mathbf{v}}_j$ is defined such that $Q(t^{n+1-j})M\mathbf{v}^{n+1-j} = M\tilde{\mathbf{v}}_j$
thus enabling the summation expression to be found by solving the initial value problem 
\begin{align}
    \begin{split}
    M\frac{d\tilde{\mathbf{v}}_j}{ds} &= -C(\tilde{\mathbf{v}}_j(s))\tilde{\mathbf{v}}_j(s) , \qquad t^{n+1-j}\leq s\leq t^{n+1}\\
    \tilde{\mathbf{v}}_j(t^{n+1-j}) &= \mathbf{v}(t^{n+1-j}).
    \end{split}
    \label{eq:IVP}
\end{align}
Notice how the integrational factor $Q(t)$ is never evaluated directly.

The final scheme applied for solving~\ref{eq:NSoperator} when applying OIFS consists of one implicit scheme for 
solving~\ref{eq:NSOIFS1} and an explicit scheme for solving~\ref{eq:IVP}. When applied in this thesis the 
first scheme is an implicit BDFk-scheme while the second is an explicit 4th order Runge-Kutta scheme. 

%It is important to add that the error induced by this method is non-vanishing and is only recommended for assuring stability 
%for very instable problem. 

\subsection{Fractional step} 
\label{fracstep}

Fractional step is an algorithm that can be divided into four separate steps. For simplicity let us write the N-S
equations as 
\begin{align}
    \partial_t v = -Av + Dp - Cv.
    \label{eq:NSfracstep}
\end{align}
Where $\partial_t, A,D,C$ Denotes the time-derivate, linear, gradient and non-linear operator. 
%The method describing one time-step can then be summarized as following
%\begin{itemize}
    %\item solve $v^* = v^n + \Delta t Nv^n$.
    %\item solve the poisson pressure equation $\Delta\: p = \nabla \cdot (v^*/\Delta t)$.
    %\item solve $v^{**} =v^* + \Delta t Dp^{n+1}$.
    %\item solve $\partial_t v^{n+1}=v^{**} + \Delta t Lv^{n+1}$.
%\end{itemize}
%\begin{itemize}
    %\item Calculate the intermediate solution $v^*$ by solving $\frac{dv}{dt}=Nv$
    %\item Calculate $p^{n+1}$ by solving the poisson pressure equation $\Delta\: p = \nabla \cdot \frac{v^*}{\Delta t}$.
    %\item Calculate the intermediate velocity $v^{**}$ by solving $\frac{dv}{dt} =Dp^{n+1}$.
    %\item Calculate $v^{n+1}$ by solving $\partial_t v^{n+1}=v^{**} + \Delta t Lv^{n+1}$.
%\end{itemize}
A schematic overview of the method is stated below, where the equations on the right hand side are 
solved and the updated solution is stated on the left hand side.
\begin{align}
    \begin{split}
        v^* &\leftarrow \frac{dv}{dt}=Cv,\\
    p^{n+1} &\leftarrow \Delta\: p = \nabla \cdot \frac{v^*}{\Delta t},\\
    v^{**} &\leftarrow  \frac{dv^*}{dt} =Dp^{n+1},\\
    v^{n+1} &\leftarrow \frac{dv^{**}}{dt}= -Av^{**}.
    \end{split}
    \label{eq:fracstep}
\end{align}

As earlier mentioned this method is convenient because it allows us to handle the different 
terms with different solution techniques. So since the first equation in~\ref{eq:fracstep}
involves the non-linear skew-symmetric advection operator this equation is solved using a 
explicit Adam Bashford scheme. The second equation is the Possion pressure equation which
assures a divergence free velocity field. Note that $p\in L^2\supset H^1$ hence the Poisson equation 
is somewhat different from the one normally studied in textbooks. Another difficulty is the 
treatment of the boundary conditions. Ideally the BC's should be determined by the velocity 
field $v^{n+1}$, but since this solution is yet to be calculated the intermediate velocity field 
$v^{*}$ is used to impose the boundary conditions. With $p^{n+1}$ known the third equation is 
simply an update of the velocity in order to impose the divergence free condition. Now the last
equation is solved implicitly due to its nice symmetric structure. This results in a system 
equivalent to the Helmholtz problem which will be discussed in detail in chapter~\ref{numerics}.
This can be easily shown by discretizing the equation, 
\begin{align}
    \begin{split}
    (v^{n+1}-v^{n})/\Delta t  &= -Av^{n+1},\\
    Av^{n+1}+\frac{1}{\Delta t} v^{n+1} &= v^{n}.
    \end{split}
    \label{eq:fracHelm}
\end{align}
Knowing that $A$ is the discrete Laplacian and $v^n$ is a known variable this is 
similar to problem~\ref{eq:Helmholtz}.


This method provides an efficient algorithm, but is known to produce errors of order O(1).
The problem is the pressure Poisson equation which is solved with incorrect boundary 
conditions. The first step can also be evaluated in an OIFS-way to gain stability,
by rewriting the initial equation as described in the previous chapter. This allows you 
to solve the unstable advection operator with multiple substeps. Explicitly the first step 
in~\ref{eq:fracstep} would be solved by applying the discretization used in~\ref{eq:NSOIFS1}
with an empty right hand side since the rest of the terms are take care of in the next steps. 
The IVP~\ref{eq:IVP} is then solved to obtain $v^{*}$.

%\subsection{Pressure-correction}

