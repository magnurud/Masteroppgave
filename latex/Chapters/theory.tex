% Chapter 3 - Numerical algorithms

\chapter{Numerical algorithms} % Main chapter title

\label{theory} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

\lhead{Chapter 3. \emph{background on numerical methods}} % Change X to a consecutive number; this is for the header on each page - perhaps a shortened title

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

\section{Galerkin formulation}
Throughout this thesis all numerical methods will be based on the Galerkin formulation. Let us consider a general bounary value problem (BVP)
\begin{align}
	\begin{split}
	\mathcal{L}u =& f \;\; \text{ in } \Omega\\
	\mathcal{B}u =& g \;\; \text{ on } \partial\Omega.
	\end{split}
	\label{eq:BVP}
\end{align}
The domain $\Omega$ is a closed subspace of $\mathbb{R}^d$, $\mathcal{L}: X(\Omega)\rightarrow Y(\Omega)$ and $\mathcal{B}: X(\partial\Omega)\rightarrow B(\partial\Omega)$ are two linear operators,
$f\in Y(\Omega)$ and $g\in B(\partial\Omega)$ are known functions and $u \in X(\Omega)$ is the wanted solution. 
The space $X(\Omega)$ will be denoted as the search space. A weak formulation can now be obtained by multiplying the first equation in \ref{eq:BVP} 
by a test function $v \in X^t(\Omega)$ and integrating over the domain $\Omega$. By choosing $X^t(\Omega) = X(\Omega)$ the Galerkin formulation is obtained.
For more examples and information on this subject the first chapters in \cite{Quarteroni} are recommended. 

By the Lax-Milgram theorem it is known that a BVP is well-posed if the Operator $\mathcal{L}$ is both bounded and coersive.   

Solving the BVP numerically involves choosing discrete subsets of $X,X^t,Y,B$. These will be denoted $X_h,X_h^t,Y_h,B_h$.
The discrete subspaces can be chosen in a number of ways and the defining basis functions vary from one numerical method to another. 
In this thesis the spectral and finite element basis will be shortly stated and the spectral element basis will be viewed in more detail.

\section{Finite element method}

Finite element method is one of the most widely used numerical methods applied on problems within construction, flow simulation and many 
other areas. It offers a precise mathematical foundation and due to the connectivity properties of the elements 
it guaranties a sparse system. The decomposition of the geometrical domain into a finite amount of elements chosen according to the problem 
wanted to solve, makes it possible to create general algorithms applicable to all kinds of geometries. 
For the full mathematical foundation of FEM it will be referred to \cite{Quarteroni}, but some of the key propertie will be stated here
in order to provide a thourough understanding of the spectral element method. 

FEM provides an alorithm for solving any well-posed BVP \ref{eq:BVP} and the mathematical formulation is obtained by first finding the Galerkin
formulation and choosing a discrete subset $X^p_h(\Omega) \subset X(\Omega)$ spanned by the finite element basis functions ${\phi^p_i}$.
$p$ denotes the polynomial degree of the basis-functions, in 1D and for $p=1$ the basis functions are defined as
\[ \phi_i(x) =
    \begin{cases}
        \frac{x-x_i}{x_i-x_{i-1}}  & \quad \text{if } x_{i-1}\leq x \leq x_i, \\
        \frac{x_{i+1}-x}{x_{i+1}-x_i}  & \quad \text{if } x_{i}\leq x \leq x_{i+1}, \\
        0  & \quad \text{otherwise}. \\
    \end{cases}
\]
Notice that $\text{supp}(\phi_i) = [x_{i-1},x_{i+1}]$ and as a consequence of this $(\phi_i,\phi_j)_{\Omega} = 0 \text{ if } |i-j| > 1 $. 
These qualities is what gives rise to the resulting sparse linear system. 
By increasing the polynomial order the number of gridpoints used to define the polynomial will need to increase as well.
This implies either reducing the distance between the gridpoints or increasing the support of each basis function.
Both aproaches will reduce the sparsity of the final matrix.
Another key aspect of FEM is the treatment of the domain $\Omega$, 
on which a triangulization $\{\mathcal{T}_h\}$ is defined such that the original domain is divided into elements.
By defining a reference element ($[-1,1]$ in 1D) and a general mapping function, all the local contributions can be calculated by a 
generalized quadrature rule before being added to the global system of equations. This is a process tailored for parallelization, and can 
be generalized for a wide range of problems.

FEM is called a projection method since the solution $u_h\in X^h$ is a projection
of the actual solution $u$ of the BVP onto the discrete space $X^h$. Provided that the initial BVP is well-posed there exists to 
constants $M,\alpha>0$ known as the bounded and coercivity constant such that the error of the solution can be reduced to a pure 
interpolation error. The result is known as Cea's lemma,  
\begin{align}
    ||u-u_h||_X \leq \frac{M}{\alpha}||u-I_hu||_X.
    \label{eq:Cea}
\end{align}
Where $I_h$ is the projection operator. 

Before this section ends it is important to understand the two ways to improve the error and the effects these two ways have on the algorithm. 
Assume the solution of the BVP to be infinitely smooth and let $h$ denote the general size of the elements
and $p$ the order of the polynomial basis that defines $X^h$. Roughly speaking the error is given as $e = Ch^p$ with $C$ being some constant.
This is not a formal truth but rather a guideline as to how the error behaves, factors such as geometric complexity, condition-number,non-linear
operators and the regularity of the solution will all provide slightly more complicated error estimates. 
However for a simpler BVP such as $u,f,g \in C^{\infty}(\Omega), \Omega = [-1,1]^d, \mathcal{L} = -\Delta,\mathcal{B} = 1$ the error estimate is valid.  
performing a $h$-refinement will lead to an algebraic convergence, while the sparsity of the system is conserved
and the total algorithm does not change in any other way than increasing the number of elements.
Keeping $h$ constant and increasing $p$ will provide spectral convergence, but the sparsity will be reduced and all integrals solved will require 
quadrature rules of higher order. A more formal statement and numerical validation can be found in \cite{Karniadakis} chapter 2.6.  

%-----------------------------------
%	SUBSECTION 1
%-----------------------------------
\section{Spectral methods}
Spectral methods (SM) share a some of the mathematical ideas as FEM, but are not as widely used in real life problems. 
There are many ways to apply SM, 
and in this thesis only the Galerkin version with numerical integration (known as G-NI) will be considered and will be referred to only as SM. 
For a full introduction to SM and its applications to BVP see \cite{Canuto}.
SM can be reduced to a interpolation problem such as FEM, and are very interesting from a theoretical point of view due to its 
spectral convergence rate which allows you to obtain solutions of extremely high accuracy. 
The most important draw-back of SM are the difficulties with applications to complex geometries. Allthough the system of equations surging from
a BVP can be constructed in an elegant way it is rarely sparse and often result in expensive calculations. 

For a BVP in one dimension SM defines a set of basis functions $\{\psi_i\}_N$ which spans the whole domain $\Omega$. 
The discrete space $X_h(\Omega)$ spanned by the basis functions involves all polynomials up to degree $N$.
A function $u$ is projected onto $X_h$ by the relation

\begin{align}
    u_h(x) = \sum_{i=0}^N a_i\psi_i(x).
    \label{eq:spectralprojection}
\end{align}
Where the coefficients $a_i$ are called the expansion coefficients. There are many possible choices for the basis and the belonging coefficients, 
in this thesis and the algorithms used the functions $\psi_i$ will be the Lagrange polynomials based on the Gauss-Lobatto-Legendre (GLL) nodes. 
The GLL-nodes are given as the solutions of the equation 
\begin{align}
    (1-\xi^2)L_N'(\xi) = 0.
    \label{eq:GLL-nodes}
\end{align}
$L_N$ being the Legendre polynomial of degree $N$, defined from the Sturm-Louville problem
\begin{align}
    \frac{d}{dx}\left[  (1-x^2)\frac{d}{dx}L_n(x)\right]+n(n+1)L_n(x) = 0.
    \label{eq:Legendre}
\end{align}
With equations \ref{eq:Legendre} and \ref{eq:GLL-nodes} the basis functions $\psi_j$ can be stated as 
\begin{align}
    \psi_j = \prod_{i\neq j}^{N}\frac{x-x_i}{x_j-x_i}.
    \label{eq:Lagrange}
\end{align}
\colorbox{yellow}{This should be taken a bit more thouroughly, Quadrature! }

$\{x_i\}$ beeing the solutions to \ref{eq:GLL-nodes}. Note that $\psi_j(x_i) = 0 \text{ when } i \neq j$,
the expansion coefficients in \ref{eq:spectralprojection} are then chosen as $a_i = u_i :=u(x_i)$ to minimize the projection error in $L^2(\Omega)$. 
expanding a basis such that the coefficients are simply the evaluation of the function in that particular point, is known as a nodal SM. 
Creating a basis for 2 and 3 dimensions is done simply by taking the cross product of the basis functions in each direction
\begin{align}
    \Psi_{ijk}(x,y,z) = \psi_i(x)\psi_j(y)\psi_k(z).
    \label{eq:3dbasis}
\end{align}
In order to clarify some of the concepts the SM approach will be applied on the Helmholtz equation
%
\begin{align}
    -\Delta u + \lambda u &= f \quad \text{in } \Omega, \\
    u &= 0 \quad \text{on } \partial \Omega.
    \label{eq:Helmholtz}
\end{align}
%
$\Omega$ will for this example be defined as the unit square $[-1,1]^2$. 
Let us start by defining the space $V =H^1_0(\Omega)$ and assuming $f\in L^2(\Omega)$. The weak formulation after applying the divergence theorem is the given as

Find $u\in V$ st. 
%
\begin{align}
    \int_{\Omega}\nabla u \cdot \nabla v \partial \Omega + \lambda \int_{\Omega} u v\partial \Omega 
    &= \int_{\Omega}f v\partial \Omega \qquad \forall v \in V
    \label{eq:Helmholtzweak}
\end{align}
%
In order to solve this using SM the discrete space $V_h \subset V$ is defined as $\text{span}\{\psi_i\}$ following the preceding definitions 
the discrete weak formulation is stated as 
Find $u_h\in V_h$ st. 
%
\begin{align}
    \sum_i\left(  u_i\int_{\Omega}\nabla \psi_i \cdot \nabla \psi_j \partial \Omega + u_i\lambda \int_{\Omega} \psi_i \psi_j\partial \Omega \right)
    &= \int_{\Omega}f \psi_j\partial \Omega \qquad \forall \psi_j \in V_h.
    \label{eq:Helmholtzdiscrete}
\end{align}
%
The following step of this particular SM method is evaluating the integrals by using the GLL-quadrature rule, the resulting system of equations 
is then given as 
%
\begin{align}
    \sum_i\left(  u_i\sum_k \rho_k\nabla \psi_i(\mathbf{x}_{k}) \cdot \nabla \psi_j(\mathbf{x}_{k}) + u_i\lambda \sum_k \rho_k \psi_i(\mathbf{x}_{k}) \psi_j(\mathbf{x}_{k})\right)\\
     = \sum_k \rho_kf \psi_j(\mathbf{x}_{k})\qquad \forall \psi_j(\mathbf{x}_{k}) \in V_h.
    \label{eq:Helmholtzquad}
\end{align}
%
$\rho_k$ is the quadrature weight for the kth node, and $\mathbf{x}_k$ is the vector containing the coordinates to the kth node.
Note that all the indices $i,j,k=1,\cdots,N_xN_y$.
This can be written in a compact matrix form as 
\begin{align}
    (A+\lambda M)u_h = \tilde f.
    \label{eq:Helmholtzmat}
\end{align}
Where the elements in the matrices and vectors are given as 
\begin{align}
    \begin{split}
        A_{ij} &= \sum_k \rho_k\nabla \psi_i(\mathbf{x}_{k}) \cdot \nabla \psi_j(\mathbf{x}_{k}),\\
        M_{ij} &= \sum_k \rho_k \psi_i(\mathbf{x}_{k}) \psi_j(\mathbf{x}_{k}) = \rho_i\delta_{ij},\\
        (u_h)_i & = u(\mathbf{x}_i), \\
        \tilde f_j &= \sum_k \rho_k f(\mathbf{x}_{k}) \psi_j(\mathbf{x}_{k}) = \rho_j f(\mathbf{x}_{j}).
    \end{split}
    \label{eq:Helmholtzmatelem}
\end{align}
From these equations it is clear that the mass matrix $M$ is diagonal and the rhs vector $\tilde f$ is easily calculated, 
while the stiffness matrix $A$ is symmetric but full.

\colorbox{yellow}{some figures or references to illustrate this}

\begin{itemize}
\item quadrature rule
\item the choice of nodes and basis functions
\item sparsity for different operators
\item the role of the jacobian 
\item cross product formulations

\end{itemize}

\cite{Canuto}

%-----------------------------------
%	SUBSECTION 2
%-----------------------------------

\section{Spectral element method}
In the early 1980's the the idea to combine FEM and SM came along in order to obtain the robustness and resulting sparse system of FEM 
combined with the spectral convergence rate provided by SM. 
The result was the Spectral element method. An example of Read articles\ldots Several formulations was investigated  and the development of super computers has played an important role in deciding the method applied today. The basic idea is to divide the domain 
of the BVP wanted to solve into elements as in FEM and then use spectral basis functions of higher degree with support only within one element. 

In the previous subsection the power of spectral methods was illustrated on the unit square in two dimensions.
But the limitations when it comes to more complex geometry rapidly affects the spectral convergence rate. 
Let $\hat{\Omega}$ be the reference element $[-1,1]^d$,
the standard procedure when working on a deformed geometry $\Omega$ with SM is to first create a map $\mathcal{F}:\hat{\Omega}\rightarrow\Omega$.
The jacobian is then given as the transposed tensor derivative of $\mathcal{F}$
\begin{align}
    \mathbf{J} &= (\nabla \otimes \mathcal{F})^T =
\begin{bmatrix}
    \frac{\partial \mathcal{F}_1}{\partial x} &  \frac{\partial \mathcal{F}_1}{\partial y}  \\ 	
	\frac{\partial \mathcal{F}_2}{\partial x} &  \frac{\partial \mathcal{F}_2}{\partial y} \\ 	
\end{bmatrix},\\
J &= \text{det}(\mathbf{J}).
    \label{eq:jaobian}
\end{align}
This allows us to transform both derivatives and integrals to the reference domain, let $\boldsymbol\xi = [\xi,\eta]^T$ denote the axis in the reference 
domain corresponding to $\mathbf{x} = [x,y]^T$ in the deformed domain. The transformation is performed according to the following identities
\begin{align}
    \begin{split}
        d\mathbf{x} &= \mathbf{J}d\boldsymbol\xi \\
        \int_{\Omega}f(\mathbf{x})d\mathbf{x} &= \int_{\hat\Omega}\hat f J d\boldsymbol\xi \\
        \nabla u &= \mathbf{J}^{-T}\hat\nabla \hat u.
    \end{split}
    \label{eq:transforms}
\end{align}
Here $\hat u,\hat f$ are obtain by simply substituting $\mathbf{x}$ with $\mathcal{F}(\boldsymbol{\xi})$ and $\hat \nabla $ is the partial 
differential operator wrt. $\boldsymbol\xi$. The important thing to notice here is that whenever an integral is solved and a derivative is 
introduced the Jacobian appears in the equation. When applying the GLL-quadrature to solve the integrals equality is guaranteed iff the 
function integrated is of polynomial degree $2n-1$ or less, and the error gets bigger with increasing polynomial degree.

By dividing the domain up into smaller elements ${\Omega_e}$ the initial deformation of the full domain $\Omega$ 
can be reduced to have a very small effect on the each of the elements.


%$\Omega$ is some 2 dimensional strongly connected domain with well-defined corners and each of the edges can be described by some polynomial $\Gamma_i$.

\begin{itemize}
\item READ LITERATURE ON THIS !! 
\end{itemize}
\subsection{Filtering}
When choosing a polynomial space with a not sufficiently high degree the modes tends to get spourios and the discrete solution 
\ldots By projecting parts of the higher order modes onto the polynomials of lower degree one can greatly decrease the spourious effect.
\cite{Karniadakis} Chapter 2.4
\subsection{aliasing}
When solving the non-linear term in the N-S equation the polynomial to be integrated is of order 3/2 normal \ldots
\cite{Karniadakis} Chapter 2.4

%----------------------------------------------------------------------------------------
%	SECTION 2
%----------------------------------------------------------------------------------------

